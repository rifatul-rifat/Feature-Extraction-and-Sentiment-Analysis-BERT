{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xj_ljO3rMl0h"
   },
   "source": [
    "This experiment has been conducted on google colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qJ7iSTxkBUIH",
    "outputId": "773a7ffc-ace0-461c-d098-22ba37904e92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "2UxUj1guSTY-",
    "outputId": "7775cd81-77ae-481d-afeb-70f11e38af21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RWQi0fpdM7MH"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjglFVqJUZCO"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.disable(logging.CRITICAL)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bert import tokenization\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cTlIk38mNNe5"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jIyhiaNEVBYM"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Feature Extraction and Sentiment Analysis BERT/Womens-Clothing-E-Commerce-Reviews.csv\", \n",
    "                   encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "nPV6n4BQViyx",
    "outputId": "8dc78df9-553c-461e-cac0-ab4303821c9b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dress runs small esp where the zipper area run...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This dress is perfection! so pretty and flatte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>More and more i find myself reliant on the rev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiment\n",
       "0  I had such high hopes for this dress and reall...          0\n",
       "1  I love tracy reese dresses, but this one is no...          0\n",
       "2  Dress runs small esp where the zipper area run...          0\n",
       "3  This dress is perfection! so pretty and flatte...          1\n",
       "4  More and more i find myself reliant on the rev...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "YIFLf7fo0Zou",
    "outputId": "ba1edb40-b9ed-4e0a-daaf-50e0d7d90db8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5000\n",
       "0    4000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EH9iVzI8WH_H"
   },
   "outputs": [],
   "source": [
    "X = data.reviews\n",
    "y = data.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qwkLGxv4NaiX"
   },
   "source": [
    "### Data Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "-RAkS_5pWH7x",
    "outputId": "ab1f8352-719f-49ab-e140-659a01474f9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (7200,)\n",
      "Validation shape: (900,)\n",
      "Testing shape: (900,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=0, stratify=y_val)\n",
    "\n",
    "print(\"\"\"Training shape: {}\n",
    "Validation shape: {}\n",
    "Testing shape: {}\"\"\".format(X_train.shape, X_val.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SY6ZKj4LNhUb"
   },
   "source": [
    "### Load pretrained BERT module from tensorflow hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2zjj8Ssy-pP"
   },
   "outputs": [],
   "source": [
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "bert_module = hub.Module(BERT_MODEL_HUB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_8a9KpPSNqCl"
   },
   "source": [
    "### Create Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zx3NqRJbBwSj"
   },
   "outputs": [],
   "source": [
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    \n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "        vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                        tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "    return tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybRy5aotOF6L"
   },
   "source": [
    "### Create BERT Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S69qIcPIGCLV"
   },
   "outputs": [],
   "source": [
    "def convert_sentence_to_features(sentence, tokenizer, max_seq_len):\n",
    "    tokens = ['[CLS]']\n",
    "    tokens.extend(tokenizer.tokenize(sentence))\n",
    "    if len(tokens) > max_seq_len-1:\n",
    "        tokens = tokens[:max_seq_len-1]\n",
    "    tokens.append('[SEP]')\n",
    "    \n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_mask = [1] * len(input_ids)\n",
    "    segment_ids = [0] * len(input_ids)\n",
    "    \n",
    "    zero_padding = [0] * (max_seq_len-len(input_ids))\n",
    "\n",
    "    input_ids.extend(zero_padding)\n",
    "    input_mask.extend(zero_padding)\n",
    "    segment_ids.extend(zero_padding)\n",
    "    \n",
    "    return input_ids, input_mask, segment_ids\n",
    "\n",
    "def convert_sentences_to_features(sentences, tokenizer, max_seq_len):\n",
    "    all_input_ids = []\n",
    "    all_input_mask = []\n",
    "    all_segment_ids = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        input_ids, input_mask, segment_ids = convert_sentence_to_features(sentence, tokenizer, max_seq_len)\n",
    "        all_input_ids.append(input_ids)\n",
    "        all_input_mask.append(input_mask)\n",
    "        all_segment_ids.append(segment_ids)\n",
    "    \n",
    "    return all_input_ids, all_input_mask, all_segment_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KzwEhFtDOU1r"
   },
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2zPmPdYPDRK"
   },
   "outputs": [],
   "source": [
    "def creat_BERT_embeddings(sentences, tokenizer, max_seq_len):\n",
    "    \"\"\"Create BERT Embeddings from tokenized Text\n",
    "\n",
    "    Argument: A list of Sentences\n",
    "    Return: A numpy array of BERT embeddings\n",
    "    \"\"\"\n",
    "    input_ids_vals, input_mask_vals, segment_ids_vals = convert_sentences_to_features(sentences, tokenizer, max_seq_len)\n",
    "\n",
    "    ### SIGNATURE\n",
    "    input_ids = tf.placeholder(dtype=tf.int32, shape=[None, None])\n",
    "    input_mask = tf.placeholder(dtype=tf.int32, shape=[None, None])\n",
    "    segment_ids = tf.placeholder(dtype=tf.int32, shape=[None, None])\n",
    "\n",
    "    bert_inputs = dict(\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        segment_ids=segment_ids)\n",
    "    \n",
    "    bert_outputs = bert_module(bert_inputs, signature=\"tokens\", as_dict=True)\n",
    "\n",
    "    pooled_embeddings = []\n",
    "    # sequence_embeddings = []\n",
    "\n",
    "    ### CREAT BATCH PROCESS\n",
    "    input_ids_tensors = tf.compat.v1.data.Dataset.from_tensor_slices(input_ids_vals)\n",
    "    input_mask_tensors = tf.compat.v1.data.Dataset.from_tensor_slices(input_mask_vals)\n",
    "    segment_ids_tensors = tf.compat.v1.data.Dataset.from_tensor_slices(segment_ids_vals)\n",
    "    dcombined = tf.compat.v1.data.Dataset.zip((input_ids_tensors, input_mask_tensors, segment_ids_tensors)).batch(512)\n",
    "\n",
    "    iterator = tf.compat.v1.data.make_one_shot_iterator(dcombined)\n",
    "    next_ele = iterator.get_next()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        try:\n",
    "            while True:\n",
    "                inputs = sess.run(next_ele)\n",
    "\n",
    "                input_ids_vals = inputs[0]\n",
    "                input_mask_vals = inputs[1]\n",
    "                segment_ids_vals = inputs[2]\n",
    "                out = sess.run(bert_outputs, feed_dict={input_ids: input_ids_vals,\n",
    "                                                        input_mask: input_mask_vals, \n",
    "                                                        segment_ids: segment_ids_vals})\n",
    "\n",
    "                pooled_embeddings.extend(out['pooled_output'].tolist())\n",
    "                # sequence_embeddings.extend(out['sequence_output'].tolist())\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "    return np.array(pooled_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "9zndVdQBPQc3",
    "outputId": "1249ac3c-48cd-4145-86b2-e529f06eb203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.2 s, sys: 17.2 s, total: 1min\n",
      "Wall time: 56.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_embeddings = pd.DataFrame(creat_BERT_embeddings(sentences=X_train, tokenizer=tokenizer, max_seq_len=128)).add_prefix('Col_')\n",
    "X_val_embeddings = pd.DataFrame(creat_BERT_embeddings(sentences=X_val, tokenizer=tokenizer, max_seq_len=128)).add_prefix('Col_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "obvXL-COQQH0",
    "outputId": "31ef1ca0-5a52-4ee1-c1a2-ae443e0ae720"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col_0</th>\n",
       "      <th>Col_1</th>\n",
       "      <th>Col_2</th>\n",
       "      <th>Col_3</th>\n",
       "      <th>Col_4</th>\n",
       "      <th>Col_5</th>\n",
       "      <th>Col_6</th>\n",
       "      <th>Col_7</th>\n",
       "      <th>Col_8</th>\n",
       "      <th>Col_9</th>\n",
       "      <th>Col_10</th>\n",
       "      <th>Col_11</th>\n",
       "      <th>Col_12</th>\n",
       "      <th>Col_13</th>\n",
       "      <th>Col_14</th>\n",
       "      <th>Col_15</th>\n",
       "      <th>Col_16</th>\n",
       "      <th>Col_17</th>\n",
       "      <th>Col_18</th>\n",
       "      <th>Col_19</th>\n",
       "      <th>Col_20</th>\n",
       "      <th>Col_21</th>\n",
       "      <th>Col_22</th>\n",
       "      <th>Col_23</th>\n",
       "      <th>Col_24</th>\n",
       "      <th>Col_25</th>\n",
       "      <th>Col_26</th>\n",
       "      <th>Col_27</th>\n",
       "      <th>Col_28</th>\n",
       "      <th>Col_29</th>\n",
       "      <th>Col_30</th>\n",
       "      <th>Col_31</th>\n",
       "      <th>Col_32</th>\n",
       "      <th>Col_33</th>\n",
       "      <th>Col_34</th>\n",
       "      <th>Col_35</th>\n",
       "      <th>Col_36</th>\n",
       "      <th>Col_37</th>\n",
       "      <th>Col_38</th>\n",
       "      <th>Col_39</th>\n",
       "      <th>...</th>\n",
       "      <th>Col_728</th>\n",
       "      <th>Col_729</th>\n",
       "      <th>Col_730</th>\n",
       "      <th>Col_731</th>\n",
       "      <th>Col_732</th>\n",
       "      <th>Col_733</th>\n",
       "      <th>Col_734</th>\n",
       "      <th>Col_735</th>\n",
       "      <th>Col_736</th>\n",
       "      <th>Col_737</th>\n",
       "      <th>Col_738</th>\n",
       "      <th>Col_739</th>\n",
       "      <th>Col_740</th>\n",
       "      <th>Col_741</th>\n",
       "      <th>Col_742</th>\n",
       "      <th>Col_743</th>\n",
       "      <th>Col_744</th>\n",
       "      <th>Col_745</th>\n",
       "      <th>Col_746</th>\n",
       "      <th>Col_747</th>\n",
       "      <th>Col_748</th>\n",
       "      <th>Col_749</th>\n",
       "      <th>Col_750</th>\n",
       "      <th>Col_751</th>\n",
       "      <th>Col_752</th>\n",
       "      <th>Col_753</th>\n",
       "      <th>Col_754</th>\n",
       "      <th>Col_755</th>\n",
       "      <th>Col_756</th>\n",
       "      <th>Col_757</th>\n",
       "      <th>Col_758</th>\n",
       "      <th>Col_759</th>\n",
       "      <th>Col_760</th>\n",
       "      <th>Col_761</th>\n",
       "      <th>Col_762</th>\n",
       "      <th>Col_763</th>\n",
       "      <th>Col_764</th>\n",
       "      <th>Col_765</th>\n",
       "      <th>Col_766</th>\n",
       "      <th>Col_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.659489</td>\n",
       "      <td>-0.464730</td>\n",
       "      <td>-0.957151</td>\n",
       "      <td>0.670922</td>\n",
       "      <td>0.945277</td>\n",
       "      <td>-0.298615</td>\n",
       "      <td>0.140124</td>\n",
       "      <td>0.212573</td>\n",
       "      <td>-0.861705</td>\n",
       "      <td>-0.999700</td>\n",
       "      <td>-0.605654</td>\n",
       "      <td>0.984324</td>\n",
       "      <td>0.948046</td>\n",
       "      <td>0.377068</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>-0.497775</td>\n",
       "      <td>0.245334</td>\n",
       "      <td>-0.585299</td>\n",
       "      <td>0.073094</td>\n",
       "      <td>0.828752</td>\n",
       "      <td>0.664243</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>-0.093136</td>\n",
       "      <td>0.314149</td>\n",
       "      <td>0.334059</td>\n",
       "      <td>0.993542</td>\n",
       "      <td>-0.779223</td>\n",
       "      <td>0.915568</td>\n",
       "      <td>0.843669</td>\n",
       "      <td>0.615497</td>\n",
       "      <td>-0.278391</td>\n",
       "      <td>0.118742</td>\n",
       "      <td>-0.990054</td>\n",
       "      <td>-0.158134</td>\n",
       "      <td>-0.984163</td>\n",
       "      <td>-0.977160</td>\n",
       "      <td>0.491682</td>\n",
       "      <td>-0.479324</td>\n",
       "      <td>0.058912</td>\n",
       "      <td>0.347220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180769</td>\n",
       "      <td>-0.245119</td>\n",
       "      <td>-0.294652</td>\n",
       "      <td>-0.367644</td>\n",
       "      <td>0.685810</td>\n",
       "      <td>-0.846489</td>\n",
       "      <td>-0.579735</td>\n",
       "      <td>-0.348997</td>\n",
       "      <td>0.609319</td>\n",
       "      <td>0.204738</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>-0.857483</td>\n",
       "      <td>-0.876669</td>\n",
       "      <td>-0.571752</td>\n",
       "      <td>-0.386892</td>\n",
       "      <td>0.418586</td>\n",
       "      <td>-0.258973</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.030630</td>\n",
       "      <td>-0.837558</td>\n",
       "      <td>0.699402</td>\n",
       "      <td>-0.771091</td>\n",
       "      <td>0.956840</td>\n",
       "      <td>-0.691685</td>\n",
       "      <td>-0.888869</td>\n",
       "      <td>-0.170056</td>\n",
       "      <td>0.751165</td>\n",
       "      <td>0.885666</td>\n",
       "      <td>-0.440122</td>\n",
       "      <td>-0.417689</td>\n",
       "      <td>0.632071</td>\n",
       "      <td>-0.130147</td>\n",
       "      <td>0.991678</td>\n",
       "      <td>0.745128</td>\n",
       "      <td>-0.032809</td>\n",
       "      <td>0.352095</td>\n",
       "      <td>0.702057</td>\n",
       "      <td>-0.953417</td>\n",
       "      <td>-0.630775</td>\n",
       "      <td>0.868778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.567957</td>\n",
       "      <td>-0.450326</td>\n",
       "      <td>-0.780838</td>\n",
       "      <td>0.408273</td>\n",
       "      <td>0.579154</td>\n",
       "      <td>-0.090489</td>\n",
       "      <td>0.404886</td>\n",
       "      <td>0.285569</td>\n",
       "      <td>-0.289359</td>\n",
       "      <td>-0.999791</td>\n",
       "      <td>-0.325130</td>\n",
       "      <td>0.806307</td>\n",
       "      <td>0.966448</td>\n",
       "      <td>0.221185</td>\n",
       "      <td>0.857770</td>\n",
       "      <td>-0.258594</td>\n",
       "      <td>0.619497</td>\n",
       "      <td>-0.625398</td>\n",
       "      <td>0.350537</td>\n",
       "      <td>0.707224</td>\n",
       "      <td>0.623491</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>0.238879</td>\n",
       "      <td>0.364654</td>\n",
       "      <td>0.388217</td>\n",
       "      <td>0.784246</td>\n",
       "      <td>-0.573318</td>\n",
       "      <td>0.908454</td>\n",
       "      <td>0.889738</td>\n",
       "      <td>0.708217</td>\n",
       "      <td>-0.253570</td>\n",
       "      <td>0.229095</td>\n",
       "      <td>-0.988088</td>\n",
       "      <td>-0.245612</td>\n",
       "      <td>-0.871597</td>\n",
       "      <td>-0.989617</td>\n",
       "      <td>0.396455</td>\n",
       "      <td>-0.499493</td>\n",
       "      <td>-0.011006</td>\n",
       "      <td>0.184007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189193</td>\n",
       "      <td>-0.274724</td>\n",
       "      <td>-0.354285</td>\n",
       "      <td>-0.469935</td>\n",
       "      <td>0.679869</td>\n",
       "      <td>-0.551901</td>\n",
       "      <td>-0.607671</td>\n",
       "      <td>-0.321371</td>\n",
       "      <td>0.512774</td>\n",
       "      <td>0.241593</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>-0.688180</td>\n",
       "      <td>-0.585825</td>\n",
       "      <td>-0.206715</td>\n",
       "      <td>-0.336971</td>\n",
       "      <td>0.532936</td>\n",
       "      <td>-0.005770</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.172926</td>\n",
       "      <td>-0.381800</td>\n",
       "      <td>0.659361</td>\n",
       "      <td>-0.413921</td>\n",
       "      <td>0.699115</td>\n",
       "      <td>-0.083048</td>\n",
       "      <td>-0.899891</td>\n",
       "      <td>-0.401575</td>\n",
       "      <td>0.639334</td>\n",
       "      <td>0.531187</td>\n",
       "      <td>-0.429557</td>\n",
       "      <td>-0.039638</td>\n",
       "      <td>0.566836</td>\n",
       "      <td>0.550733</td>\n",
       "      <td>0.766385</td>\n",
       "      <td>0.746976</td>\n",
       "      <td>0.336601</td>\n",
       "      <td>0.401434</td>\n",
       "      <td>0.655184</td>\n",
       "      <td>-0.717869</td>\n",
       "      <td>-0.712284</td>\n",
       "      <td>0.847127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.778795</td>\n",
       "      <td>-0.346610</td>\n",
       "      <td>-0.902236</td>\n",
       "      <td>0.531263</td>\n",
       "      <td>0.782789</td>\n",
       "      <td>-0.197437</td>\n",
       "      <td>0.377878</td>\n",
       "      <td>0.104080</td>\n",
       "      <td>-0.851841</td>\n",
       "      <td>-0.999705</td>\n",
       "      <td>-0.538332</td>\n",
       "      <td>0.974979</td>\n",
       "      <td>0.949982</td>\n",
       "      <td>0.351784</td>\n",
       "      <td>0.865813</td>\n",
       "      <td>-0.371862</td>\n",
       "      <td>0.156277</td>\n",
       "      <td>-0.538143</td>\n",
       "      <td>0.218601</td>\n",
       "      <td>0.621527</td>\n",
       "      <td>0.620110</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.027218</td>\n",
       "      <td>0.234407</td>\n",
       "      <td>0.413431</td>\n",
       "      <td>0.991349</td>\n",
       "      <td>-0.763888</td>\n",
       "      <td>0.890116</td>\n",
       "      <td>0.863652</td>\n",
       "      <td>0.659295</td>\n",
       "      <td>-0.198865</td>\n",
       "      <td>0.107730</td>\n",
       "      <td>-0.987395</td>\n",
       "      <td>-0.086717</td>\n",
       "      <td>-0.951600</td>\n",
       "      <td>-0.979777</td>\n",
       "      <td>0.386455</td>\n",
       "      <td>-0.403794</td>\n",
       "      <td>0.294576</td>\n",
       "      <td>0.305212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117183</td>\n",
       "      <td>-0.310559</td>\n",
       "      <td>-0.343416</td>\n",
       "      <td>-0.494404</td>\n",
       "      <td>0.747040</td>\n",
       "      <td>-0.752267</td>\n",
       "      <td>-0.510656</td>\n",
       "      <td>-0.408162</td>\n",
       "      <td>0.636763</td>\n",
       "      <td>0.078393</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>-0.810404</td>\n",
       "      <td>-0.909096</td>\n",
       "      <td>-0.581506</td>\n",
       "      <td>-0.362381</td>\n",
       "      <td>0.397921</td>\n",
       "      <td>-0.180872</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.206304</td>\n",
       "      <td>-0.714427</td>\n",
       "      <td>0.704334</td>\n",
       "      <td>-0.809210</td>\n",
       "      <td>0.852820</td>\n",
       "      <td>-0.577445</td>\n",
       "      <td>-0.877410</td>\n",
       "      <td>-0.120543</td>\n",
       "      <td>0.718491</td>\n",
       "      <td>0.840978</td>\n",
       "      <td>-0.460720</td>\n",
       "      <td>-0.380659</td>\n",
       "      <td>0.517358</td>\n",
       "      <td>-0.317557</td>\n",
       "      <td>0.988715</td>\n",
       "      <td>0.731808</td>\n",
       "      <td>0.293118</td>\n",
       "      <td>0.324444</td>\n",
       "      <td>0.605280</td>\n",
       "      <td>-0.817181</td>\n",
       "      <td>-0.652367</td>\n",
       "      <td>0.846241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.724027</td>\n",
       "      <td>-0.349603</td>\n",
       "      <td>-0.934234</td>\n",
       "      <td>0.500797</td>\n",
       "      <td>0.820521</td>\n",
       "      <td>-0.162249</td>\n",
       "      <td>0.585874</td>\n",
       "      <td>0.100884</td>\n",
       "      <td>-0.807700</td>\n",
       "      <td>-0.999935</td>\n",
       "      <td>-0.212136</td>\n",
       "      <td>0.953452</td>\n",
       "      <td>0.936226</td>\n",
       "      <td>0.366095</td>\n",
       "      <td>0.835880</td>\n",
       "      <td>-0.501214</td>\n",
       "      <td>-0.002248</td>\n",
       "      <td>-0.539310</td>\n",
       "      <td>0.040113</td>\n",
       "      <td>0.471419</td>\n",
       "      <td>0.549526</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.092836</td>\n",
       "      <td>0.117571</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>0.984580</td>\n",
       "      <td>-0.592104</td>\n",
       "      <td>0.819739</td>\n",
       "      <td>0.889904</td>\n",
       "      <td>0.678030</td>\n",
       "      <td>-0.298469</td>\n",
       "      <td>-0.015760</td>\n",
       "      <td>-0.977880</td>\n",
       "      <td>-0.044367</td>\n",
       "      <td>-0.958167</td>\n",
       "      <td>-0.980254</td>\n",
       "      <td>0.261360</td>\n",
       "      <td>-0.599832</td>\n",
       "      <td>0.103838</td>\n",
       "      <td>0.169739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058251</td>\n",
       "      <td>-0.189173</td>\n",
       "      <td>-0.259440</td>\n",
       "      <td>-0.349394</td>\n",
       "      <td>0.798764</td>\n",
       "      <td>-0.779730</td>\n",
       "      <td>-0.398215</td>\n",
       "      <td>-0.379223</td>\n",
       "      <td>0.706953</td>\n",
       "      <td>0.130084</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>-0.835167</td>\n",
       "      <td>-0.816031</td>\n",
       "      <td>-0.365787</td>\n",
       "      <td>-0.243654</td>\n",
       "      <td>0.213036</td>\n",
       "      <td>-0.331720</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.036632</td>\n",
       "      <td>-0.532156</td>\n",
       "      <td>0.711096</td>\n",
       "      <td>-0.792048</td>\n",
       "      <td>0.906653</td>\n",
       "      <td>-0.559458</td>\n",
       "      <td>-0.919063</td>\n",
       "      <td>0.079833</td>\n",
       "      <td>0.594124</td>\n",
       "      <td>0.763141</td>\n",
       "      <td>-0.452002</td>\n",
       "      <td>-0.573433</td>\n",
       "      <td>0.602281</td>\n",
       "      <td>0.379347</td>\n",
       "      <td>0.974111</td>\n",
       "      <td>0.611260</td>\n",
       "      <td>0.600111</td>\n",
       "      <td>0.261441</td>\n",
       "      <td>0.686410</td>\n",
       "      <td>-0.902852</td>\n",
       "      <td>-0.473035</td>\n",
       "      <td>0.827135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.908149</td>\n",
       "      <td>-0.569470</td>\n",
       "      <td>-0.996126</td>\n",
       "      <td>0.915152</td>\n",
       "      <td>0.963255</td>\n",
       "      <td>-0.250603</td>\n",
       "      <td>0.860438</td>\n",
       "      <td>0.349019</td>\n",
       "      <td>-0.976684</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.932177</td>\n",
       "      <td>0.991449</td>\n",
       "      <td>0.935429</td>\n",
       "      <td>0.855076</td>\n",
       "      <td>0.907463</td>\n",
       "      <td>-0.854554</td>\n",
       "      <td>-0.213438</td>\n",
       "      <td>-0.669507</td>\n",
       "      <td>0.324293</td>\n",
       "      <td>-0.002271</td>\n",
       "      <td>0.755913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.582461</td>\n",
       "      <td>0.392748</td>\n",
       "      <td>0.607291</td>\n",
       "      <td>0.999589</td>\n",
       "      <td>-0.922741</td>\n",
       "      <td>0.927927</td>\n",
       "      <td>0.925030</td>\n",
       "      <td>0.699714</td>\n",
       "      <td>-0.657172</td>\n",
       "      <td>0.297713</td>\n",
       "      <td>-0.984647</td>\n",
       "      <td>-0.420417</td>\n",
       "      <td>-0.995937</td>\n",
       "      <td>-0.989566</td>\n",
       "      <td>0.702664</td>\n",
       "      <td>-0.730054</td>\n",
       "      <td>0.015209</td>\n",
       "      <td>0.021079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662394</td>\n",
       "      <td>-0.561816</td>\n",
       "      <td>-0.540575</td>\n",
       "      <td>-0.710651</td>\n",
       "      <td>0.864900</td>\n",
       "      <td>-0.723948</td>\n",
       "      <td>-0.786676</td>\n",
       "      <td>-0.689634</td>\n",
       "      <td>0.822122</td>\n",
       "      <td>0.373334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.968438</td>\n",
       "      <td>-0.993598</td>\n",
       "      <td>-0.719559</td>\n",
       "      <td>-0.580187</td>\n",
       "      <td>0.548467</td>\n",
       "      <td>-0.672335</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.234993</td>\n",
       "      <td>-0.940505</td>\n",
       "      <td>0.933753</td>\n",
       "      <td>-0.965160</td>\n",
       "      <td>0.986422</td>\n",
       "      <td>-0.913600</td>\n",
       "      <td>-0.977074</td>\n",
       "      <td>-0.352261</td>\n",
       "      <td>0.725661</td>\n",
       "      <td>0.959849</td>\n",
       "      <td>-0.587544</td>\n",
       "      <td>-0.867890</td>\n",
       "      <td>0.786355</td>\n",
       "      <td>-0.857022</td>\n",
       "      <td>0.998797</td>\n",
       "      <td>0.826229</td>\n",
       "      <td>-0.763918</td>\n",
       "      <td>-0.327413</td>\n",
       "      <td>0.773089</td>\n",
       "      <td>-0.973204</td>\n",
       "      <td>-0.716175</td>\n",
       "      <td>0.904148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Col_0     Col_1     Col_2  ...   Col_765   Col_766   Col_767\n",
       "0 -0.659489 -0.464730 -0.957151  ... -0.953417 -0.630775  0.868778\n",
       "1 -0.567957 -0.450326 -0.780838  ... -0.717869 -0.712284  0.847127\n",
       "2 -0.778795 -0.346610 -0.902236  ... -0.817181 -0.652367  0.846241\n",
       "3 -0.724027 -0.349603 -0.934234  ... -0.902852 -0.473035  0.827135\n",
       "4 -0.908149 -0.569470 -0.996126  ... -0.973204 -0.716175  0.904148\n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_embeddings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tdERWWeGOd9y"
   },
   "source": [
    "### Create Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xodI3Gk1S7G8"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Dense(units=768, input_dim=768, activation=tf.nn.tanh),\n",
    "                                    tf.keras.layers.Dense(units=512, activation=tf.nn.tanh),\n",
    "                                    tf.keras.layers.Dense(units=512, activation=tf.nn.tanh),\n",
    "                                    tf.keras.layers.Dense(units=2, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KDYLJ-OPYatA"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "P09FFBObZe-a",
    "outputId": "ac7f76dc-e26f-4066-82a2-9622e1fbd301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7200 samples, validate on 900 samples\n",
      "Epoch 1/3\n",
      "7200/7200 [==============================] - 0s 13us/sample - loss: 0.3372 - acc: 0.8489 - val_loss: 0.3990 - val_acc: 0.8267\n",
      "Epoch 2/3\n",
      "7200/7200 [==============================] - 0s 12us/sample - loss: 0.3472 - acc: 0.8438 - val_loss: 0.3476 - val_acc: 0.8478\n",
      "Epoch 3/3\n",
      "7200/7200 [==============================] - 0s 13us/sample - loss: 0.3358 - acc: 0.8461 - val_loss: 0.3566 - val_acc: 0.8456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f28ed7df470>"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = tf.keras.callbacks.History()\n",
    "\n",
    "y_train_k = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
    "y_val_k = tf.keras.utils.to_categorical(y_val, num_classes=2)\n",
    "\n",
    "model.fit(X_train_embeddings, y_train_k, \n",
    "          validation_data=(X_val_embeddings, y_val_k), \n",
    "          epochs=3,\n",
    "          batch_size=2000,\n",
    "          callbacks=[history],\n",
    "          shuffle=True,\n",
    "          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "XJFY8IzaYamt",
    "outputId": "b643f131-0e81-4ca8-9627-6c859a72a6d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.08 s, sys: 2.01 s, total: 9.09 s\n",
      "Wall time: 8.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test_embeddings = pd.DataFrame(creat_BERT_embeddings(sentences=X_test, tokenizer=tokenizer, max_seq_len=128)).add_prefix('Col_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MJzFoLWiYajG"
   },
   "outputs": [],
   "source": [
    "y_test_k = tf.keras.utils.to_categorical(y_test, num_classes=2)\n",
    "loss, test_accuracy = model.evaluate(X_test_embeddings, y_test_k, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pmtXw5OcPGO5"
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_g8-206CfWlw",
    "outputId": "3002e300-13e2-4575-9517-da6807b4e401"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.861\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(np.array(X_test_embeddings))\n",
    "acc = accuracy_score(y_test_k.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "print(\"Prediction Accuracy:\", round(acc, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xM4Yv-yTPPlx"
   },
   "source": [
    "### Result & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qicr3vWacNdh"
   },
   "outputs": [],
   "source": [
    "# for visualization\n",
    "his_train_acc = history.history['acc']\n",
    "his_val_acc = history.history['val_acc']\n",
    "\n",
    "his_train_loss = history.history['loss']\n",
    "his_val_loss = history.history['val_loss']\n",
    "\n",
    "train_accuracy = round(history.history['acc'][-1], 3)\n",
    "val_accuracy = round(history.history['val_acc'][-1], 3)\n",
    "test_accuracy = round(test_accuracy, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "id": "yriNksBkKJs5",
    "outputId": "c4aa6382-ecd4-45c7-e190-92a8bb70640a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>\n",
       "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
       "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
       "            <div id=\"0795866f-aa30-4e10-8d55-bddd7a7bece6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                \n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"0795866f-aa30-4e10-8d55-bddd7a7bece6\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '0795866f-aa30-4e10-8d55-bddd7a7bece6',\n",
       "                        [{\"cells\": {\"align\": \"left\", \"font\": {\"size\": 15}, \"height\": 25, \"values\": [[\"Training\", \"Validation\", \"Test\"], [\"0.846\", \"0.846\", \"0.861\"]]}, \"domain\": {\"x\": [0.0, 0.46499999999999997], \"y\": [0.54, 1.0]}, \"header\": {\"align\": \"left\", \"fill\": {\"color\": \"rgb(55, 83, 109)\"}, \"font\": {\"color\": \"white\", \"size\": 15}, \"height\": 30, \"values\": [\"\", \"Accuracy\"]}, \"type\": \"table\"}, {\"automargin\": true, \"domain\": {\"x\": [0.5349999999999999, 0.9999999999999999], \"y\": [0.54, 1.0]}, \"hole\": 0.5, \"labels\": [\"Positive\", \"Negative\"], \"name\": \"Sentiment\", \"type\": \"pie\", \"values\": [5000, 4000]}, {\"line\": {\"color\": \"darkorange\"}, \"name\": \"Training\", \"type\": \"scatter\", \"x\": [1, 2, 3], \"xaxis\": \"x\", \"y\": [0.8488888740539551, 0.84375, 0.8461111187934875], \"yaxis\": \"y\"}, {\"line\": {\"color\": \"seagreen\"}, \"name\": \"Validation\", \"type\": \"scatter\", \"x\": [1, 2, 3], \"xaxis\": \"x\", \"y\": [0.8266666531562805, 0.847777783870697, 0.8455555438995361], \"yaxis\": \"y\"}, {\"line\": {\"color\": \"darkorange\"}, \"name\": \"Training\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1, 2, 3], \"xaxis\": \"x2\", \"y\": [0.3371541268295712, 0.3472491486204995, 0.33575845261414844], \"yaxis\": \"y2\"}, {\"line\": {\"color\": \"seagreen\"}, \"name\": \"Validation\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1, 2, 3], \"xaxis\": \"x2\", \"y\": [0.39901235699653625, 0.3476431965827942, 0.35662662982940674], \"yaxis\": \"y2\"}],\n",
       "                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Results\", \"x\": 0.23249999999999998, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Unique Categories Distribution\", \"x\": 0.7674999999999998, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Accuracy Vs Epochs\", \"x\": 0.23249999999999998, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.46, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Loss Vs Epochs\", \"x\": 0.7674999999999998, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.46, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Sentiment Analysis Result\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.46499999999999997], \"showgrid\": true, \"title\": {\"text\": \"Epochs\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.5349999999999999, 0.9999999999999999], \"showgrid\": true, \"title\": {\"text\": \"Epochs\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 0.46], \"showgrid\": true, \"title\": {\"text\": \"Accuracy\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.46], \"showgrid\": true, \"title\": {\"text\": \"Loss\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0795866f-aa30-4e10-8d55-bddd7a7bece6');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                \n",
       "            </script>\n",
       "        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ---------------------- Sub-Plots --------------------\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    shared_xaxes=False,\n",
    "    vertical_spacing=0.08,\n",
    "    horizontal_spacing=0.07,\n",
    "    subplot_titles=(\"Results\", \"Unique Categories Distribution\", \"Accuracy Vs Epochs\", \"Loss Vs Epochs\"),\n",
    "    specs=[[{\"type\": \"table\"}, {\"type\": \"pie\"}],\n",
    "           [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}]]\n",
    ")\n",
    "\n",
    "# ---------------------- Table -----------------------\n",
    "fig.add_trace(\n",
    "    go.Table(\n",
    "        header=dict(\n",
    "            values=[\"\", \"Accuracy\"],\n",
    "            font=dict(size=15, color='white'),\n",
    "            align=\"left\",\n",
    "            height = 30,\n",
    "            fill={'color':'rgb(55, 83, 109)'}),\n",
    "        cells=dict(\n",
    "            values=[[\"Training\", \"Validation\", \"Test\"],\n",
    "                    [str(train_accuracy), str(val_accuracy), str(test_accuracy)]],\n",
    "            font=dict(size=15),\n",
    "            align = \"left\",\n",
    "            height = 25,\n",
    "            # fill = {'color':'red'}\n",
    "            )\n",
    "    ),\n",
    "    row = 1, col = 1)\n",
    "\n",
    "# ---------------------- Pie -------------------------\n",
    "fig.add_trace(\n",
    "      go.Pie(labels=['Positive', 'Negative'],\n",
    "             values=[5000, 4000], \n",
    "             name=\"Sentiment\", \n",
    "             hole=0.5, \n",
    "            #  pull=[0.2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "             automargin=True),\n",
    "    row=1, col=2)\n",
    "\n",
    "# ---------------------- Line Plot -------------------\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=list(range(1,len(his_train_acc)+1)),\n",
    "               y=his_train_acc,\n",
    "               name=\"Training\",\n",
    "               line=dict(color=\"darkorange\")),\n",
    "    row=2, col = 1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=list(range(1,len(his_val_acc)+1)),\n",
    "               y=his_val_acc,\n",
    "               name=\"Validation\",\n",
    "               line=dict(color=\"seagreen\")),\n",
    "    row=2, col = 1)\n",
    "\n",
    "fig.update_xaxes(title_text=\"Epochs\", showgrid=True, row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Accuracy\", showgrid=True, row=2, col=1)\n",
    "\n",
    "# ----------------------- Line Plot -------------------\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=list(range(1,len(his_train_loss)+1)),\n",
    "               y=his_train_loss,\n",
    "               name=\"Training\",\n",
    "               line=dict(color=\"darkorange\"),\n",
    "               showlegend=False),\n",
    "    row=2, col = 2)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=list(range(1,len(his_val_loss)+1)),\n",
    "               y=his_val_loss,\n",
    "               name=\"Validation\",\n",
    "               line=dict(color=\"seagreen\"),\n",
    "               showlegend=False),\n",
    "    row=2, col = 2)\n",
    "\n",
    "fig.update_xaxes(title_text=\"Epochs\", showgrid=True, row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"Loss\", showgrid=True, row=2, col=2)\n",
    "\n",
    "# Set title\n",
    "fig.update_layout(\n",
    "    # template=\"plotly_dark\",\n",
    "    title_text=\"Sentiment Analysis Result\"\n",
    "    # height=800,\n",
    "    # showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lrFJh-UAKt0H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Feature Extraction and Sentiment Analysis-BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
